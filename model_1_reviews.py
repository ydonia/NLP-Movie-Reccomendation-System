# -*- coding: utf-8 -*-
"""Model 1 - Reviews.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1oVDs-FJ8LhMEj7qouimasW3dE9vnKPJ9

1st model is sentiment analysis on whether the move is good or bad, based on the Critics' Consensus on Rotten Tomatoes. We have a dataset on huggingface that does something very similar - rates a sentence to classify it as positive or negative, and the Critics' Consensus is also about a sentence in length.

1. Take our HuggingFace dataset as training dataset (it seems to be already pre-processed)
2. Create a sentiment analyis neural network by following a guide. If you want to do a sentiment analysis practice project, by implementing one that's on an article. For example on Machine Learning Mastery, there are often simple projects that are easy to run with all coding available.
3. Train the model on the HuggingFace data. Check the accuracy and how it is performing - it should be evaluating the sentences based on "positive" or "negative". https://huggingface.co/datasets/rotten_tomatoes
4. Test it on the Rotten Tomatoes dataset, on the category called "Critics Consensus", and evaluate performance. https://www.kaggle.com/stefanoleone992/rotten-tomatoes-movies-and-critic-reviews-dataset?select=rotten_tomatoes_movies.csv
-- Hemal
"""

!pip install datasets
import numpy as np
import tensorflow as tf
import pandas as pd
from tensorflow.keras import Sequential
from tensorflow.keras.layers import LSTM, Dropout, Dense, Embedding
from keras.models import Sequential
from keras.preprocessing.text import Tokenizer
from keras.preprocessing import sequence
from keras.datasets import imdb

max_features = 20000
max_len = 20
batch_size = 100

(X_train, y_train), (X_test, y_test) = imdb.load_data(num_words = max_features)

X_train = sequence.pad_sequences(X_train)
X_test = sequence.pad_sequences(X_test)

print(X_train.shape)
print(X_test.shape)

model = Sequential()
model.add(Embedding(max_features, 100))
model.add(LSTM(units = 20, activation = 'tanh'))
model.add(Dense(1, activation = 'sigmoid'))
model.compile(loss= 'binary_crossentropy', optimizer= 'adam', metrics= ['accuracy'])

model.summary()

model.fit(X_train, y_train, epochs = 15, batch_size = 100, validation_data = (X_test, y_test))
score, accuracy = model.evaluate(X_test, y_test, batch_size = batch_size)
print('Score: ', score)
print('Accuracy: ', accuracy)

model.save('sentiment.h5')